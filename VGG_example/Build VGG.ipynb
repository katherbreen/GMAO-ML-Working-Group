{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do I build a neural net I read about in a paper and adapt it to my problem?\n",
    "\n",
    "<img src=\"conv.gif\">\n",
    "Image source: https://medium.datadriveninvestor.com/convolutional-neural-networks-3b241a5da51e\n",
    "\n",
    "## Need the following information:\n",
    "\n",
    "### Architectural \n",
    "- Number of convolutional layers\n",
    "- Filter/stride/padding for each conv layer\n",
    "- Number of dense (i.e. fully connected) layers\n",
    "- Number of nodes per dense layer\n",
    "- Other: \n",
    "    - most conv nets use max pooling following some (not neccessarily all) conv layers, they will have a filter size/stride/padding\n",
    "    - BatchNormalization layers are common, other normalization schemes might be used (local response normalization; LRN)\n",
    "    - Dropout layers are also common, need to know dropout ratio (usually between 0.1 and 0.5 - this is a hyperparameter!)\n",
    "    \n",
    "### Additional info/parameters\n",
    "- batch size\n",
    "- dropout ratio\n",
    "- learning rate\n",
    "- optimizer\n",
    "- activation function\n",
    "\n",
    "## VGG\n",
    "For this tutorial, build VGG-11 (Simonyan et. al., 2015). **Note that ImageNet (or any image-recognition task) is a classification problem (i.e. \"this is a cat\"), but we will convert the network to perform regression tasks ($y=f(x)$) by altering the last dense layer so that the output activation function is \"linear\" ($\\mathcal{L}=y-\\hat{y}$) and the number of output nodes is equal to the number of features in our prediction.** For ImageNet, the number of output nodes is 1000, because that's how many different classes are in the dataset (\"fox\", \"dog\", \"car\", etc...). For our regression problem, the number of nodes in the final dense layer will be equal to the number of pixels/grid cells in the target ($\\mathbf{Y}$) data.\n",
    "\n",
    "For this tutorial, we'll assume we have an input of shape (224, 224, 3) and an output of (224, 224, 1). The I/O features mean that we are predicting a single feature that we assume is parameterized by three input features. For example, if we are predicting precipitation amount (one feature), input features might be temperature, pressure, and relative humidity. Each 224x224 \"image\" represents, in our precipitation thought experiment, a 224x224 spatial grid (lat/lon for a given time step).\n",
    "\n",
    "### Data dimensions\n",
    "If you've worked with NNs yourself, then you've probably heard of ImageNet. ImageNet is a benchmark dataset used in the ImageNet Large-ScaleVisual Recognition Challenge (ILSVRC). Many popular networks have been developed using this dataset - it's considered a benchmark dataset, like MNIST. The image dimensions are (224,224,3) -> (image height, image width, number of channels). The word \"channels\" can be confusing, and can often be replaced with the word \"features\", and represents the depth of the image. For example, an RGB image has a depth of 3, i.e. 3 channels. The data for your problem is likely a different shape, so some parameters from the original network will have to be tweaked to fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the structure first\n",
    "Often there will be a table or a diagram showing which layers are used, what order they go in, and some (but not all!) of the parameters. In Table 1 from Simonyan et. al., we'll use the most shallow network (left-most column), with a total of 11 weighted layers - 8 conv and 3 dense layers. Note that pooling, dropout, and normalization layers don't require weights to be learned.\n",
    "\n",
    "Table 1 denotes conv layers using the format \"conv-receptive field size-number of channels\". The receptive field is the filter size for each layer, and the number of channels is the number of channels in the output from that layer. For example, \"conv3-64\" means that the convolutional layer uses a filter of size 3, and outputs data in shape (new_height, new_width, 64). The formula to calculate new dimensions after a convolution is:\n",
    "\n",
    "$$\n",
    "dim_{new} = \\frac{dim_{old} + 2p -f}{s} + 1\n",
    "$$\n",
    "\n",
    "where:\n",
    "    f = filter size\n",
    "    s = stride\n",
    "    p = padding\n",
    "    \n",
    "Often, padding and/or stride will not be explicitly stated in the text, but can be inferred.\n",
    "\n",
    "<img src=\"VGG_table1_box.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-11 structure\n",
    "\n",
    "**NOTE:** The code sample below shows the structure of VGG11 using *only* the parameters specified in Table 1. We will have to mine through the text for the rest of the network parameters.\n",
    "\n",
    "```Python\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# INPUT\n",
    "input_img = keras.Input(shape=(224, 224, 3))\n",
    "# CONV1\n",
    "x = layers.Conv2D(64, 3, activation=?, padding=?)(input_img)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(?)(x)\n",
    "# CONV2\n",
    "x = layers.Conv2D(128, 3, activation=?, padding=?)(x)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(?)(x)\n",
    "# CONV3\n",
    "x = layers.Conv2D(256, 3, activation=?, padding=?)(x)\n",
    "# CONV4\n",
    "x = layers.Conv2D(256, 3, activation=?, padding=?)(x)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(?)(x)\n",
    "# CONV5\n",
    "x = layers.Conv2D(512, 3, activation=?, padding=?)(x)\n",
    "# CONV6\n",
    "x = layers.Conv2D(512, 3, activation=?, padding=?)(x)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(?)(x)\n",
    "# CONV7\n",
    "x = layers.Conv2D(512, 3, activation=?, padding=?)(x)\n",
    "# CONV8\n",
    "x = layers.Conv2D(512, 3, activation=?, padding=?)(x)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(?)(x)\n",
    "# FLATTEN\n",
    "x = layers.Flatten()(x)\n",
    "# DENSE1\n",
    "x = layers.Dense(4096, activation=?)(x)\n",
    "# DENSE2\n",
    "x = layers.Dense(4096, activation=?)(x)\n",
    "# DENSE3\n",
    "x = layers.Dense(224*224*1, activation=?)(x)\n",
    "output = layers.Reshape((224,224,1), input_shape=(224*224*1,))(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"VGG_architecture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on max pooling and padding in Keras - from Keras docs\n",
    "\n",
    "<img src=\"Keras_maxpool.png\">\n",
    "\n",
    "## For a conv and dense layers - info on padding from Keras docs\n",
    "padding: one of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input. (https://keras.io/api/layers/convolution_layers/convolution2d/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT image shape:  (?, 224, 224, 3)\n",
      "CONV1 output shape:  (?, 224, 224, 64)\n",
      "WARNING:tensorflow:From C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "MP1 output shape:  (?, 112, 112, 64)\n",
      "CONV2 output shape:  (?, 112, 112, 128)\n",
      "MP1 output shape:  (?, 56, 56, 128)\n",
      "CONV3 output shape:  (?, 56, 56, 256)\n",
      "CONV4 output shape:  (?, 56, 56, 256)\n",
      "MP2 output shape:  (?, 28, 28, 256)\n",
      "CONV5 output shape:  (?, 28, 28, 512)\n",
      "CONV6 output shape:  (?, 28, 28, 512)\n",
      "MP3 output shape:  (?, 14, 14, 512)\n",
      "CONV7 output shape:  (?, 14, 14, 512)\n",
      "CONV8 output shape:  (?, 14, 14, 512)\n",
      "MP4 output shape:  (?, 7, 7, 512)\n",
      "DENSE1 output shape:  (?, 4096)\n",
      "DENSE2 output shape:  (?, 4096)\n",
      "DENSE3 output shape:  (?, 50176)\n",
      "OUTPUT shape:  (?, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# INPUT\n",
    "input_img = keras.Input(shape=(224, 224, 3))\n",
    "print('INPUT image shape: ',input_img.shape)\n",
    "# CONV1\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(input_img)\n",
    "print('CONV1 output shape: ',x.shape)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP1 output shape: ',x.shape)\n",
    "# CONV2\n",
    "x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "print('CONV2 output shape: ',x.shape)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP1 output shape: ',x.shape)\n",
    "# CONV3\n",
    "x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "print('CONV3 output shape: ',x.shape)\n",
    "# CONV4\n",
    "x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "print('CONV4 output shape: ',x.shape)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP2 output shape: ',x.shape)\n",
    "# CONV5\n",
    "x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "print('CONV5 output shape: ',x.shape)\n",
    "# CONV6\n",
    "x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "print('CONV6 output shape: ',x.shape)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP3 output shape: ',x.shape)\n",
    "# CONV7\n",
    "x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "print('CONV7 output shape: ',x.shape)\n",
    "# CONV8\n",
    "x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "print('CONV8 output shape: ',x.shape)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP4 output shape: ',x.shape)\n",
    "# FLATTEN\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# DENSE1\n",
    "x = layers.Dense(4096, activation='relu')(x)\n",
    "print('DENSE1 output shape: ',x.shape)\n",
    "# DENSE2\n",
    "x = layers.Dense(4096, activation='relu')(x)\n",
    "print('DENSE2 output shape: ',x.shape)\n",
    "# DENSE3\n",
    "x = layers.Dense(224*224*1, activation='linear')(x)  # this would be a softmax layer for a classification problem\n",
    "print('DENSE3 output shape: ',x.shape)\n",
    "output = layers.Reshape((224,224,1), input_shape=(224*224*1,))(x)  # reshape the 2D Dense output to resemble 3D img\n",
    "print('OUTPUT shape: ',output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters\n",
    "\n",
    "<img src=\"VGG_train.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT image shape:  (?, 224, 224, 3)\n",
      "WARNING:tensorflow:From C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "CONV1 output shape:  (?, 224, 224, 64)\n",
      "MP1 output shape:  (?, 112, 112, 64)\n",
      "CONV2 output shape:  (?, 112, 112, 128)\n",
      "MP1 output shape:  (?, 56, 56, 128)\n",
      "CONV3 output shape:  (?, 56, 56, 256)\n",
      "CONV4 output shape:  (?, 56, 56, 256)\n",
      "MP2 output shape:  (?, 28, 28, 256)\n",
      "CONV5 output shape:  (?, 28, 28, 512)\n",
      "CONV6 output shape:  (?, 28, 28, 512)\n",
      "MP3 output shape:  (?, 14, 14, 512)\n",
      "CONV7 output shape:  (?, 14, 14, 512)\n",
      "CONV8 output shape:  (?, 14, 14, 512)\n",
      "MP4 output shape:  (?, 7, 7, 512)\n",
      "DENSE1 output shape:  (?, 4096)\n",
      "DENSE2 output shape:  (?, 4096)\n",
      "DENSE3 output shape:  (?, 50176)\n",
      "OUTPUT shape:  (?, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# new imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# INPUT\n",
    "input_img = keras.Input(shape=(224, 224, 3))\n",
    "print('INPUT image shape: ',input_img.shape)\n",
    "# CONV1\n",
    "x = layers.Conv2D(64, \n",
    "                  3, \n",
    "                  activation='relu', \n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                  bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                 )(input_img)\n",
    "print('CONV1 output shape: ',x.shape)\n",
    "# DROPOUT\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP1 output shape: ',x.shape)\n",
    "# CONV2\n",
    "x = layers.Conv2D(128,  \n",
    "                  3, \n",
    "                  activation='relu', \n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                  bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                 )(x)\n",
    "print('CONV2 output shape: ',x.shape)\n",
    "# DROPOUT\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP1 output shape: ',x.shape)\n",
    "# CONV3\n",
    "x = layers.Conv2D(256,  \n",
    "                  3, \n",
    "                  activation='relu', \n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                  bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                 )(x)\n",
    "print('CONV3 output shape: ',x.shape)\n",
    "# CONV4\n",
    "x = layers.Conv2D(256,  \n",
    "                  3, \n",
    "                  activation='relu', \n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                  bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                 )(x)\n",
    "print('CONV4 output shape: ',x.shape)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP2 output shape: ',x.shape)\n",
    "# CONV5\n",
    "x = layers.Conv2D(512,  \n",
    "                  3, \n",
    "                  activation='relu', \n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                  bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                 )(x)\n",
    "print('CONV5 output shape: ',x.shape)\n",
    "# CONV6\n",
    "x = layers.Conv2D(512,  \n",
    "                  3, \n",
    "                  activation='relu', \n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                  bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                 )(x)\n",
    "print('CONV6 output shape: ',x.shape)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP3 output shape: ',x.shape)\n",
    "# CONV7\n",
    "x = layers.Conv2D(512,  \n",
    "                  3, \n",
    "                  activation='relu', \n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                  bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                 )(x)\n",
    "print('CONV7 output shape: ',x.shape)\n",
    "# CONV8\n",
    "x = layers.Conv2D(512,  \n",
    "                  3, \n",
    "                  activation='relu', \n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                  bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                 )(x)\n",
    "print('CONV8 output shape: ',x.shape)\n",
    "# MAX POOLING\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "print('MP4 output shape: ',x.shape)\n",
    "# FLATTEN\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# DENSE1\n",
    "x = layers.Dense(4096, \n",
    "                 activation='relu',\n",
    "                 kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                 bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                )(x)\n",
    "print('DENSE1 output shape: ',x.shape)\n",
    "# DENSE2\n",
    "x = layers.Dense(4096,\n",
    "                 activation='relu',\n",
    "                 kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                 bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                )(x)\n",
    "print('DENSE2 output shape: ',x.shape)\n",
    "# DENSE3\n",
    "x = layers.Dense(224*224*1,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.0025),\n",
    "                 bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(5*10e-4)\n",
    "                )(x)  # this would be a softmax layer for a classification problem\n",
    "print('DENSE3 output shape: ',x.shape)\n",
    "output = layers.Reshape((224,224,1), input_shape=(224*224*1,))(x)  # reshape the 2D Dense output to resemble 3D img\n",
    "print('OUTPUT shape: ',output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khbreen\\Anaconda3\\envs\\python37env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 128 samples, validate on 16 samples\n",
      "Epoch 1/5\n",
      "128/128 [==============================] - 126s 983ms/step - loss: 10.8256 - val_loss: 9.7503\n",
      "Epoch 2/5\n",
      "128/128 [==============================] - 100s 784ms/step - loss: 8.6228 - val_loss: 7.4007\n",
      "Epoch 3/5\n",
      "128/128 [==============================] - 100s 784ms/step - loss: 6.4737 - val_loss: 5.5283\n",
      "Epoch 4/5\n",
      "128/128 [==============================] - 101s 792ms/step - loss: 4.8534 - val_loss: 4.1761\n",
      "Epoch 5/5\n",
      "128/128 [==============================] - 100s 779ms/step - loss: 3.6987 - val_loss: 3.2228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ed71e1a4c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some synthetic data to use for the purposes of this example\n",
    "# NOTE - I made this tutorial on my local machine, which doesn't have a lot of memory. The number of samples used below (axis=0) are too small to be practical - 10K samples would be more appropriate for training\n",
    "x_train = np.random.randn(128,224,224,3)\n",
    "y_train = np.random.randn(128,224,224,1)\n",
    "x_val = np.random.randn(16,224,224,3)\n",
    "y_val = np.random.randn(16,224,224,1)\n",
    "\n",
    "# define, compile and train the model\n",
    "from keras.optimizers import SGD  # stochastic gradient descent\n",
    "# define model object\n",
    "model = keras.Model(input_img,output)  # the arguments are the layers defined in the cell above that have the I/O data\n",
    "# compile model\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=10e-2, momentum=0.9),\n",
    "    loss='mean_squared_error'  \n",
    "    )\n",
    "# NOTE: the paper uses the SGD optimizer. The network was trained by manually reducing the learning rate. Other optimizers automatically do this, such as Adam.\n",
    "\n",
    "# train\n",
    "model.fit(\n",
    "    x_train, y_train,  # training I/O\n",
    "    epochs=5,  # small number used in development\n",
    "    batch_size=8,#256,  # batch size adjusted for demo only\n",
    "    validation_data=(x_val,y_val) # validation occurs at the end of each training epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50176)             205571072 \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 224, 224, 1)       0         \n",
      "=================================================================\n",
      "Total params: 334,337,408\n",
      "Trainable params: 334,337,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
